{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178,
     "referenced_widgets": [
      "7c676819d0bc46deab79af55576cb680",
      "6b0b2a196cf04039aae27141cbb342b8",
      "8841468b83e14fc793f090f195562ecc",
      "e85aa133d0024c7d918d19d49ebfda1f",
      "f2aab9cbec914614958c8429ff658730",
      "0f42b149c38040799aa77a06e1be37a3",
      "88e2fe42ee704457951b0a433aa7e6c3",
      "d8bdade393b64daeaa3211d74b7962ff",
      "f23de0e1ffc8491fae098ba5f55c2e00",
      "aca0418d6fe24fa3a9a9c939ad83c012",
      "7d8dff2afdfe41968ee79c9acdbdcb42"
     ]
    },
    "executionInfo": {
     "elapsed": 15166,
     "status": "ok",
     "timestamp": 1709912219824,
     "user": {
      "displayName": "송우석",
      "userId": "17544301414917834266"
     },
     "user_tz": -540
    },
    "id": "YrLNgZU9f1tt",
    "outputId": "d84850ec-9313-40fc-d257-29708e675fdf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooseok/anaconda3/envs/peft/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import torch, pandas, torch.nn, tempfile,os,pickle\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from accelerate import Accelerator\n",
    "from tuning import get_model_architecture,get_model\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = 'cuda'\n",
    "\n",
    "#tuning_names = [\"full_ft\",\"prefix\",\"prompt\",\"lora\"]\n",
    "#model_name = [\"llama\",\"dialogpt\"]\n",
    "\n",
    "tuning_name = \"full_ft\"\n",
    "model_name = \"llama\"\n",
    "\n",
    "tokenizer,model = get_model(model_name,device)\n",
    "model = get_model_architecture(tuning_name, model_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tisVWC8P5mm7"
   },
   "outputs": [],
   "source": [
    "def collate_fn(samples):\n",
    "    input_ids = [torch.LongTensor(sample.tokens) for sample in samples]\n",
    "    mask = [torch.LongTensor(sample.mask) for sample in samples]\n",
    "    labels = [torch.LongTensor(sample.labels) for sample in samples]\n",
    "\n",
    "    slen = torch.LongTensor([ len(sample.tokens) for sample in samples ])\n",
    "    max_slen = max(slen)\n",
    "    padded_input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True,\n",
    "                                                      padding_value = tokenizer.pad_token_id)\n",
    "    padded_mask = torch.nn.utils.rnn.pad_sequence(mask, batch_first=True).type(torch.float32)\n",
    "    padded_labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True,\n",
    "                                                      padding_value = -100)\n",
    "\n",
    "    attention_mask = (torch.arange(max_slen)[None, :] < slen[:, None]).type(torch.long)\n",
    "\n",
    "\n",
    "    return {'input_ids': padded_input_ids.contiguous(),\n",
    "            'mask': padded_mask.contiguous(),\n",
    "            'attention_mask': attention_mask,\n",
    "           'labels': padded_labels.contiguous()}\n",
    "TextDataExample = namedtuple('TextDataExample', ['dialogue', 'tokens', 'mask','labels'])\n",
    "with open('preprocessed_datasets_llama.pickle', 'rb') as fr:\n",
    "    datasets = pickle.load(fr)\n",
    "train_ds, valid_ds, test_ds = datasets['train'][:5000] ,datasets['valid'][:500],datasets['test'][:2000]\n",
    "\n",
    "batch_size = 10\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "train_dl = DataLoader(train_ds,batch_size = batch_size, collate_fn = collate_fn,shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds,batch_size = batch_size, collate_fn = collate_fn,shuffle = True)\n",
    "test_dl = DataLoader(test_ds,batch_size = batch_size, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-Q5Ig74c5mrw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "lr = 1e-4\n",
    "WARMUP_PROPORTION = 0.05\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "train_steps = n_epochs * (len(datasets['train']) // batch_size + 1)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "     num_warmup_steps=int(train_steps * WARMUP_PROPORTION), # learning rate 조절하는거래\n",
    "    num_training_steps=n_epochs * (len(datasets['train']) // batch_size + 1))\n",
    "\n",
    "accelerator = Accelerator(gradient_accumulation_steps=gradient_accumulation_steps)\n",
    "model, optimizer, training_dataloader, scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dl, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 24501800,
     "status": "error",
     "timestamp": 1709943879363,
     "user": {
      "displayName": "송우석",
      "userId": "17544301414917834266"
     },
     "user_tz": -540
    },
    "id": "1Eq0UeGj5m4J",
    "outputId": "a9d14011-77d3-4f3a-f040-b90e58d07651",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [1:01:42<00:00,  7.40s/it]\n",
      "Epoch 0 Validation: 100%|███████████████████████| 50/50 [02:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 4.1753833699226375 valid_loss:  4.107889900207519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [1:02:39<00:00,  7.52s/it]\n",
      "Epoch 1 Validation: 100%|███████████████████████| 50/50 [02:06<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 4.1774588475227326 valid_loss:  4.1265633678436275\n",
      "*******경고*******loss 안 줄어든다!!!!!!!!*******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [1:03:34<00:00,  7.63s/it]\n",
      "Epoch 2 Validation: 100%|███████████████████████| 50/50 [02:01<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 4.178846688747405 valid_loss:  4.1230002117156985\n",
      "*******경고*******loss 안 줄어든다!!!!!!!!*******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [1:03:12<00:00,  7.58s/it]\n",
      "Epoch 3 Validation: 100%|███████████████████████| 50/50 [02:04<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 4.1741813492774975 valid_loss:  4.10860969543457\n",
      "*******경고*******loss 안 줄어든다!!!!!!!!*******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [1:02:38<00:00,  7.52s/it]\n",
      "Epoch 4 Validation: 100%|███████████████████████| 50/50 [02:01<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 4.17718098974228 valid_loss:  4.111264171600342\n",
      "*******경고*******loss 안 줄어든다!!!!!!!!*******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [1:03:30<00:00,  7.62s/it]\n",
      "Epoch 5 Validation: 100%|███████████████████████| 50/50 [02:04<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 4.1771445441246025 valid_loss:  4.1189279460906985\n",
      "*******경고*******loss 안 줄어든다!!!!!!!!*******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████▋               | 314/500 [40:18<23:52,  7.70s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,labels \u001b[38;5;241m=\u001b[39m labels)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m---> 17\u001b[0m \u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()   \u001b[38;5;66;03m###############################\u001b[39;00m\n\u001b[1;32m     19\u001b[0m lr_scheduler\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m###############################\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/peft/lib/python3.9/site-packages/accelerate/accelerator.py:2001\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2001\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/peft/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/peft/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "best_valid_loss =float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    average_train_loss = 0.0\n",
    "\n",
    "    for index, batch in enumerate(tqdm(train_dl, ncols=80)): ###############################\n",
    "        with accelerator.accumulate(model):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device) # input이랑, am은 마지막꺼 하나뗌\n",
    "            labels = batch['labels'].to(device) # label은 처음거 하나뗌\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask,labels = labels)\n",
    "            loss = outputs.loss\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()   ###############################\n",
    "            lr_scheduler.step()  ###############################\n",
    "            optimizer.zero_grad() ###############################\n",
    "            average_train_loss += loss.item()/len(train_dl)   ###############################\n",
    "\n",
    "    #average_train_loss = train_loss_sum / len(train_dl) ######################\n",
    "    train_losses.append(average_train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    valid_loss_sum = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dl, ncols=80, desc=f'Epoch {epoch} Validation'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device) # input이랑, am은 마지막꺼 하나뗌\n",
    "            labels = batch['labels'].to(device) # label은 처음거 하나뗌\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask,labels = labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            valid_loss_sum += loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    average_valid_loss = valid_loss_sum / len(valid_dl)\n",
    "    valid_losses.append(average_valid_loss)\n",
    "    \n",
    "    print(\"train_loss:\",average_train_loss,\"valid_loss: \",average_valid_loss)\n",
    "    \n",
    "    #Early stopping\n",
    "    if average_valid_loss < best_valid_loss:\n",
    "        best_valid_loss = average_valid_loss\n",
    "        if epoch !=0:\n",
    "            torch.save(model.state_dict(), '{}.pt'.format(tuning_name))\n",
    "\n",
    "    else:\n",
    "        print(\"*******경고*******loss 안 줄어든다!!!!!!!!*******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WQbmaTH5nCU"
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs = range(1,epoch+2 )\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs,np.array(train_losses),label ='training loss')\n",
    "ax.plot(epochs, np.array(valid_losses), label = 'validation loss' )\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JU8dz0k3JnKd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOBGc3WgJTvwgp7jiBxY7Pp",
   "machine_shape": "hm",
   "mount_file_id": "1PV25_eTqPr-jNz23RBXDrs1KICBozvHF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0f42b149c38040799aa77a06e1be37a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b0b2a196cf04039aae27141cbb342b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f42b149c38040799aa77a06e1be37a3",
      "placeholder": "​",
      "style": "IPY_MODEL_88e2fe42ee704457951b0a433aa7e6c3",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "7c676819d0bc46deab79af55576cb680": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b0b2a196cf04039aae27141cbb342b8",
       "IPY_MODEL_8841468b83e14fc793f090f195562ecc",
       "IPY_MODEL_e85aa133d0024c7d918d19d49ebfda1f"
      ],
      "layout": "IPY_MODEL_f2aab9cbec914614958c8429ff658730"
     }
    },
    "7d8dff2afdfe41968ee79c9acdbdcb42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8841468b83e14fc793f090f195562ecc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8bdade393b64daeaa3211d74b7962ff",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f23de0e1ffc8491fae098ba5f55c2e00",
      "value": 2
     }
    },
    "88e2fe42ee704457951b0a433aa7e6c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aca0418d6fe24fa3a9a9c939ad83c012": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8bdade393b64daeaa3211d74b7962ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e85aa133d0024c7d918d19d49ebfda1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aca0418d6fe24fa3a9a9c939ad83c012",
      "placeholder": "​",
      "style": "IPY_MODEL_7d8dff2afdfe41968ee79c9acdbdcb42",
      "value": " 2/2 [00:05&lt;00:00,  2.43s/it]"
     }
    },
    "f23de0e1ffc8491fae098ba5f55c2e00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2aab9cbec914614958c8429ff658730": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
